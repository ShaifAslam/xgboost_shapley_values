{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa6b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "\n",
    "def kmeans(X, k, round_values=True):\n",
    "    \"\"\" Summarize a dataset with k mean samples weighted by the number of data points they\n",
    "    each represent.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy.array or pandas.DataFrame or any scipy.sparse matrix\n",
    "        Matrix of data samples to summarize (# samples x # features)\n",
    "\n",
    "    k : int\n",
    "        Number of means to use for approximation.\n",
    "\n",
    "    round_values : bool\n",
    "        For all i, round the ith dimension of each mean sample to match the nearest value\n",
    "        from X[:,i]. This ensures discrete features always get a valid value.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DenseData object.\n",
    "    \"\"\"\n",
    "\n",
    "    group_names = [str(i) for i in range(X.shape[1])]\n",
    "    if str(type(X)).endswith(\"'pandas.core.frame.DataFrame'>\"):\n",
    "        group_names = X.columns\n",
    "        X = X.values\n",
    "\n",
    "    # in case there are any missing values in data impute them\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    X = imp.fit_transform(X)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(X)\n",
    "\n",
    "    if round_values:\n",
    "        for i in range(k):\n",
    "            for j in range(X.shape[1]):\n",
    "                xj = X[:,j].toarray().flatten() if issparse(X) else X[:, j] # sparse support courtesy of @PrimozGodec\n",
    "                ind = np.argmin(np.abs(xj - kmeans.cluster_centers_[i,j]))\n",
    "                kmeans.cluster_centers_[i,j] = X[ind,j]\n",
    "    return DenseData(kmeans.cluster_centers_, group_names, None, 1.0*np.bincount(kmeans.labels_))\n",
    "\n",
    "\n",
    "class Instance:\n",
    "    def __init__(self, x, group_display_values):\n",
    "        self.x = x\n",
    "        self.group_display_values = group_display_values\n",
    "\n",
    "\n",
    "def convert_to_instance(val):\n",
    "    if isinstance(val, Instance):\n",
    "        return val\n",
    "    else:\n",
    "        return Instance(val, None)\n",
    "\n",
    "\n",
    "class InstanceWithIndex(Instance):\n",
    "    def __init__(self, x, column_name, index_value, index_name, group_display_values):\n",
    "        Instance.__init__(self, x, group_display_values)\n",
    "        self.index_value = index_value\n",
    "        self.index_name = index_name\n",
    "        self.column_name = column_name\n",
    "\n",
    "    def convert_to_df(self):\n",
    "        index = pd.DataFrame(self.index_value, columns=[self.index_name])\n",
    "        data = pd.DataFrame(self.x, columns=self.column_name)\n",
    "        df = pd.concat([index, data], axis=1)\n",
    "        df = df.set_index(self.index_name)\n",
    "        return df\n",
    "\n",
    "\n",
    "def convert_to_instance_with_index(val, column_name, index_value, index_name):\n",
    "    return InstanceWithIndex(val, column_name, index_value, index_name, None)\n",
    "\n",
    "\n",
    "def match_instance_to_data(instance, data):\n",
    "    assert isinstance(instance, Instance), \"instance must be of type Instance!\"\n",
    "\n",
    "    if isinstance(data, DenseData):\n",
    "        if instance.group_display_values is None:\n",
    "            instance.group_display_values = [instance.x[0, group[0]] if len(group) == 1 else \"\" for group in data.groups]\n",
    "        assert len(instance.group_display_values) == len(data.groups)\n",
    "        instance.groups = data.groups\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, f, out_names):\n",
    "        self.f = f\n",
    "        self.out_names = out_names\n",
    "\n",
    "\n",
    "def convert_to_model(val):\n",
    "    if isinstance(val, Model):\n",
    "        return val\n",
    "    else:\n",
    "        return Model(val, None)\n",
    "\n",
    "\n",
    "def match_model_to_data(model, data):\n",
    "    assert isinstance(model, Model), \"model must be of type Model!\"\n",
    "    \n",
    "    try:\n",
    "        if isinstance(data, DenseDataWithIndex):\n",
    "            out_val = model.f(data.convert_to_df())\n",
    "        else:\n",
    "            out_val = model.f(data.data)\n",
    "    except:\n",
    "        print(\"Provided model function fails when applied to the provided data set.\")\n",
    "        raise\n",
    "\n",
    "    if model.out_names is None:\n",
    "        if len(out_val.shape) == 1:\n",
    "            model.out_names = [\"output value\"]\n",
    "        else:\n",
    "            model.out_names = [\"output value \"+str(i) for i in range(out_val.shape[0])]\n",
    "    \n",
    "    return out_val\n",
    "\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class SparseData(Data):\n",
    "    def __init__(self, data, *args):\n",
    "        num_samples = data.shape[0]\n",
    "        self.weights = np.ones(num_samples)\n",
    "        self.weights /= np.sum(self.weights)\n",
    "        self.transposed = False\n",
    "        self.groups = None\n",
    "        self.group_names = None\n",
    "        self.groups_size = data.shape[1]\n",
    "        self.data = data\n",
    "\n",
    "\n",
    "class DenseData(Data):\n",
    "    def __init__(self, data, group_names, *args):\n",
    "        self.groups = args[0] if len(args) > 0 and args[0] is not None else [np.array([i]) for i in range(len(group_names))]\n",
    "\n",
    "        l = sum(len(g) for g in self.groups)\n",
    "        num_samples = data.shape[0]\n",
    "        t = False\n",
    "        if l != data.shape[1]:\n",
    "            t = True\n",
    "            num_samples = data.shape[1]\n",
    "\n",
    "        valid = (not t and l == data.shape[1]) or (t and l == data.shape[0])\n",
    "        assert valid, \"# of names must match data matrix!\"\n",
    "\n",
    "        self.weights = args[1] if len(args) > 1 else np.ones(num_samples)\n",
    "        self.weights /= np.sum(self.weights)\n",
    "        wl = len(self.weights)\n",
    "        valid = (not t and wl == data.shape[0]) or (t and wl == data.shape[1])\n",
    "        assert valid, \"# weights must match data matrix!\"\n",
    "\n",
    "        self.transposed = t\n",
    "        self.group_names = group_names\n",
    "        self.data = data\n",
    "        self.groups_size = len(self.groups)\n",
    "\n",
    "\n",
    "class DenseDataWithIndex(DenseData):\n",
    "    def __init__(self, data, group_names, index, index_name, *args):\n",
    "        DenseData.__init__(self, data, group_names, *args)\n",
    "        self.index_value = index\n",
    "        self.index_name = index_name\n",
    "\n",
    "    def convert_to_df(self):\n",
    "        data = pd.DataFrame(self.data, columns=self.group_names)\n",
    "        index = pd.DataFrame(self.index_value, columns=[self.index_name])\n",
    "        df = pd.concat([index, data], axis=1)\n",
    "        df = df.set_index(self.index_name)\n",
    "        return df\n",
    "\n",
    "\n",
    "def convert_to_data(val, keep_index=False):\n",
    "    if isinstance(val, Data):\n",
    "        return val\n",
    "    elif type(val) == np.ndarray:\n",
    "        return DenseData(val, [str(i) for i in range(val.shape[1])])\n",
    "    elif str(type(val)).endswith(\"'pandas.core.series.Series'>\"):\n",
    "        return DenseData(val.values.reshape((1,len(val))), list(val.index))\n",
    "    elif str(type(val)).endswith(\"'pandas.core.frame.DataFrame'>\"):\n",
    "        if keep_index:\n",
    "            return DenseDataWithIndex(val.values, list(val.columns), val.index.values, val.index.name)\n",
    "        else:\n",
    "            return DenseData(val.values, list(val.columns))\n",
    "    elif sp.sparse.issparse(val):\n",
    "        if not sp.sparse.isspmatrix_csr(val):\n",
    "            val = val.tocsr()\n",
    "        return SparseData(val)\n",
    "    else:\n",
    "        assert False, \"Unknown type passed as data object: \"+str(type(val))\n",
    "\n",
    "class Link:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class IdentityLink(Link):\n",
    "    def __str__(self):\n",
    "        return \"identity\"\n",
    "\n",
    "    @staticmethod\n",
    "    def f(x):\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def finv(x):\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LogitLink(Link):\n",
    "    def __str__(self):\n",
    "        return \"logit\"\n",
    "\n",
    "    @staticmethod\n",
    "    def f(x):\n",
    "        return np.log(x/(1-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def finv(x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "def convert_to_link(val):\n",
    "    if isinstance(val, Link):\n",
    "        return val\n",
    "    elif val == \"identity\":\n",
    "        return IdentityLink()\n",
    "    elif val == \"logit\":\n",
    "        return LogitLink()\n",
    "    else:\n",
    "        assert False, \"Passed link object must be a subclass of iml.Link\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c614f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Explanation:\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c9fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveExplanation(Explanation):\n",
    "    def __init__(self, base_value, out_value, effects, effects_var, instance, link, model, data):\n",
    "        self.base_value = base_value\n",
    "        self.out_value = out_value\n",
    "        self.effects = effects\n",
    "        self.effects_var = effects_var\n",
    "        assert isinstance(instance, Instance)\n",
    "        self.instance = instance\n",
    "        assert isinstance(link, Link)\n",
    "        self.link = link\n",
    "        assert isinstance(model, Model)\n",
    "        self.model = model\n",
    "        assert isinstance(data, Data)\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28118468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# Python 3.6.4\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import iml\n",
    "import xgboost\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def calculate_top_contributors(shap_values, features=None, feature_names=None, use_abs=False, return_df=False,\n",
    "                               n_features=5):\n",
    "    \"\"\" Adapted from the SHAP package for visualizing the contributions of features towards a prediction.\n",
    "        https://github.com/slundberg/shap\n",
    "\n",
    "        Args:\n",
    "            shap_values: np.array of floats\n",
    "            features: pandas.core.series.Series, the data with the values\n",
    "            feature_names: list, all the feature names/ column names\n",
    "            use_abs: bool, if True, will sort the data by the absolute value of the feature effect\n",
    "            return_df: bool, if True, will return a pandas dataframe, else will return a list of feature, effect, value\n",
    "            n_features: int, the number of features to report on. If it equals -1 it will return the entire dataframe\n",
    "\n",
    "        Returns:\n",
    "            if return_df is True: returns a pandas dataframe\n",
    "            if return_df is False: returns a flattened list by name, effect, and value\n",
    "        \"\"\"\n",
    "    assert not type(shap_values) == list, \"The shap_values arg looks looks multi output, try shap_values[i].\"\n",
    "    assert len(shap_values.shape) == 1, \"Expected just one row. Please only submit one row at a time.\"\n",
    "\n",
    "    shap_values = np.reshape(shap_values, (1, len(shap_values)))\n",
    "    instance = Instance(np.zeros((1, len(feature_names))), features)\n",
    "    link = convert_to_link('identity')\n",
    "\n",
    "    # explanation obj\n",
    "    expl = AdditiveExplanation(\n",
    "        shap_values[0, -1],                 # base value\n",
    "        np.sum(shap_values[0, :]),          # this row's prediction value\n",
    "        shap_values[0, :-1],                # matrix\n",
    "        None,\n",
    "        instance,                           # <iml.common.Instance object >\n",
    "        link,                               # 'identity'\n",
    "        Model(None, [\"output value\"]),  # <iml.common.Model object >\n",
    "        DenseData(np.zeros((1, len(feature_names))), list(feature_names))\n",
    "    )\n",
    "\n",
    "    # Get the name, effect and value for each feature, if there was an effect\n",
    "    features_ = {}\n",
    "    for i in range(len(expl.data.group_names)):\n",
    "        if expl.effects[i] != 0:\n",
    "            features_[i] = {\n",
    "                \"effect\": ensure_not_numpy(expl.effects[i]),\n",
    "                \"value\": ensure_not_numpy(expl.instance.group_display_values[i]),\n",
    "                \"name\": expl.data.group_names[i]\n",
    "            }\n",
    "\n",
    "    effect_df = pd.DataFrame([v for k, v in features_.items()])\n",
    "\n",
    "    if use_abs:  # get the absolute value of effect\n",
    "        effect_df['abs_effect'] = effect_df['effect'].apply(np.abs)\n",
    "        effect_df.sort_values('abs_effect', ascending=False, inplace=True)\n",
    "    else:\n",
    "        effect_df.sort_values('effect', ascending=False, inplace=True)\n",
    "    if not n_features == -1:\n",
    "        effect_df = effect_df.head(n_features)\n",
    "    if return_df:\n",
    "        return effect_df.reset_index(drop=True)\n",
    "    else:\n",
    "        list_of_info = list(zip(effect_df.name, effect_df.effect, effect_df.value))\n",
    "        effect_list = list(sum(list_of_info, ()))  # flattens the list of tuples\n",
    "        return effect_list\n",
    "\n",
    "\n",
    "def create_prediction_factors_df(contribs, X, clf):\n",
    "    \"\"\"Takes in the report df, contribs, previous eval df, and the model\n",
    "    Args:\n",
    "        contribs: numpy matrix\n",
    "        X: pandas DataFrame\n",
    "        clf: XGBoost classifier model\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame of the factors\n",
    "    \"\"\"\n",
    "\n",
    "    factors = []\n",
    "    for i, row in X.iterrows():\n",
    "        vals = calculate_top_contributors(shap_values=contribs[i, :], features=X.iloc[i, :],\n",
    "                                          feature_names=clf.feature_names)\n",
    "        factors.append(vals)\n",
    "    df = pd.DataFrame(factors, columns=['F1', 'F1_effect', 'F1_value', 'F2', 'F2_effect', 'F2_value',\n",
    "                                        'F3', 'F3_effect', 'F3_value', 'F4', 'F4_effect', 'F4_value',\n",
    "                                        'F5', 'F5_effect', 'F5_value',])\n",
    "    return df\n",
    "\n",
    "\n",
    "def ensure_not_numpy(x):\n",
    "    \"\"\"Helper function borrowed from the iml package\"\"\"\n",
    "    if isinstance(x, bytes):\n",
    "        return x.decode()\n",
    "    elif isinstance(x, np.str):\n",
    "        return str(x)\n",
    "    elif isinstance(x, np.generic):\n",
    "        return float(x.item())\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # train XGBoost model\n",
    "    X, y = shap.datasets.boston()\n",
    "    bst = xgboost.train({\"learning_rate\": 0.1}, xgboost.DMatrix(X, label=y), 100)\n",
    "\n",
    "    # explain the model's predictions using SHAP values (use pred_contrib in LightGBM)\n",
    "    shap_values = bst.predict(xgboost.DMatrix(X), pred_contribs=True)\n",
    "    # just the regular predictions\n",
    "    pred_prob = bst.predict(xgboost.DMatrix(X))\n",
    "    # or as labels\n",
    "    pred_label = np.round(pred_prob)\n",
    "\n",
    "    # for just the first observation\n",
    "    vals = calculate_top_contributors(shap_values=shap_values[10, :], features=X.iloc[10, :],\n",
    "                                          feature_names=bst.feature_names, use_abs=False)\n",
    "\n",
    "    # or as a dataframe\n",
    "    factors_df = create_prediction_factors_df(shap_values, X, clf=bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c322c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F1_effect</th>\n",
       "      <th>F1_value</th>\n",
       "      <th>F2</th>\n",
       "      <th>F2_effect</th>\n",
       "      <th>F2_value</th>\n",
       "      <th>F3</th>\n",
       "      <th>F3_effect</th>\n",
       "      <th>F3_value</th>\n",
       "      <th>F4</th>\n",
       "      <th>F4_effect</th>\n",
       "      <th>F4_value</th>\n",
       "      <th>F5</th>\n",
       "      <th>F5_effect</th>\n",
       "      <th>F5_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>5.624034</td>\n",
       "      <td>4.980</td>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>0.556319</td>\n",
       "      <td>15.30000</td>\n",
       "      <td>INDUS</td>\n",
       "      <td>0.087340</td>\n",
       "      <td>2.31000</td>\n",
       "      <td>CHAS</td>\n",
       "      <td>-0.002724</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>B</td>\n",
       "      <td>-0.026223</td>\n",
       "      <td>396.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>2.130201</td>\n",
       "      <td>9.140</td>\n",
       "      <td>NOX</td>\n",
       "      <td>0.222409</td>\n",
       "      <td>0.46900</td>\n",
       "      <td>TAX</td>\n",
       "      <td>0.198272</td>\n",
       "      <td>242.00000</td>\n",
       "      <td>CHAS</td>\n",
       "      <td>-0.002278</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>ZN</td>\n",
       "      <td>-0.003397</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>7.265620</td>\n",
       "      <td>4.030</td>\n",
       "      <td>RM</td>\n",
       "      <td>4.413855</td>\n",
       "      <td>7.18500</td>\n",
       "      <td>NOX</td>\n",
       "      <td>0.490302</td>\n",
       "      <td>0.46900</td>\n",
       "      <td>TAX</td>\n",
       "      <td>0.197083</td>\n",
       "      <td>242.00000</td>\n",
       "      <td>B</td>\n",
       "      <td>0.160604</td>\n",
       "      <td>392.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>7.146395</td>\n",
       "      <td>2.940</td>\n",
       "      <td>RM</td>\n",
       "      <td>2.769629</td>\n",
       "      <td>6.99800</td>\n",
       "      <td>TAX</td>\n",
       "      <td>0.956618</td>\n",
       "      <td>222.00000</td>\n",
       "      <td>NOX</td>\n",
       "      <td>0.442565</td>\n",
       "      <td>0.45800</td>\n",
       "      <td>AGE</td>\n",
       "      <td>0.204912</td>\n",
       "      <td>45.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>5.717870</td>\n",
       "      <td>5.330</td>\n",
       "      <td>RM</td>\n",
       "      <td>4.329943</td>\n",
       "      <td>7.14700</td>\n",
       "      <td>TAX</td>\n",
       "      <td>1.424987</td>\n",
       "      <td>222.00000</td>\n",
       "      <td>CRIM</td>\n",
       "      <td>0.528826</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>NOX</td>\n",
       "      <td>0.463377</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>1.271993</td>\n",
       "      <td>9.670</td>\n",
       "      <td>DIS</td>\n",
       "      <td>0.207549</td>\n",
       "      <td>2.47860</td>\n",
       "      <td>CRIM</td>\n",
       "      <td>0.130808</td>\n",
       "      <td>0.06263</td>\n",
       "      <td>TAX</td>\n",
       "      <td>0.071629</td>\n",
       "      <td>273.00000</td>\n",
       "      <td>B</td>\n",
       "      <td>0.062786</td>\n",
       "      <td>391.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>1.890253</td>\n",
       "      <td>9.080</td>\n",
       "      <td>DIS</td>\n",
       "      <td>0.186240</td>\n",
       "      <td>2.28750</td>\n",
       "      <td>TAX</td>\n",
       "      <td>0.031415</td>\n",
       "      <td>273.00000</td>\n",
       "      <td>ZN</td>\n",
       "      <td>0.016322</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>B</td>\n",
       "      <td>0.012697</td>\n",
       "      <td>396.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>RM</td>\n",
       "      <td>2.740492</td>\n",
       "      <td>6.976</td>\n",
       "      <td>LSTAT</td>\n",
       "      <td>2.054528</td>\n",
       "      <td>5.64000</td>\n",
       "      <td>DIS</td>\n",
       "      <td>0.266582</td>\n",
       "      <td>2.16750</td>\n",
       "      <td>CRIM</td>\n",
       "      <td>0.215512</td>\n",
       "      <td>0.06076</td>\n",
       "      <td>NOX</td>\n",
       "      <td>0.057181</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>2.618553</td>\n",
       "      <td>6.480</td>\n",
       "      <td>CRIM</td>\n",
       "      <td>0.419633</td>\n",
       "      <td>0.10959</td>\n",
       "      <td>RM</td>\n",
       "      <td>0.289580</td>\n",
       "      <td>6.79400</td>\n",
       "      <td>B</td>\n",
       "      <td>0.058909</td>\n",
       "      <td>393.45000</td>\n",
       "      <td>CHAS</td>\n",
       "      <td>-0.002730</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>0.780604</td>\n",
       "      <td>7.880</td>\n",
       "      <td>ZN</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>CHAS</td>\n",
       "      <td>-0.003765</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>B</td>\n",
       "      <td>-0.024175</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>INDUS</td>\n",
       "      <td>-0.102163</td>\n",
       "      <td>11.930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        F1  F1_effect  F1_value       F2  F2_effect  F2_value     F3  \\\n",
       "0    LSTAT   5.624034     4.980  PTRATIO   0.556319  15.30000  INDUS   \n",
       "1    LSTAT   2.130201     9.140      NOX   0.222409   0.46900    TAX   \n",
       "2    LSTAT   7.265620     4.030       RM   4.413855   7.18500    NOX   \n",
       "3    LSTAT   7.146395     2.940       RM   2.769629   6.99800    TAX   \n",
       "4    LSTAT   5.717870     5.330       RM   4.329943   7.14700    TAX   \n",
       "..     ...        ...       ...      ...        ...       ...    ...   \n",
       "501  LSTAT   1.271993     9.670      DIS   0.207549   2.47860   CRIM   \n",
       "502  LSTAT   1.890253     9.080      DIS   0.186240   2.28750    TAX   \n",
       "503     RM   2.740492     6.976    LSTAT   2.054528   5.64000    DIS   \n",
       "504  LSTAT   2.618553     6.480     CRIM   0.419633   0.10959     RM   \n",
       "505  LSTAT   0.780604     7.880       ZN   0.001974   0.00000   CHAS   \n",
       "\n",
       "     F3_effect   F3_value    F4  F4_effect   F4_value     F5  F5_effect  \\\n",
       "0     0.087340    2.31000  CHAS  -0.002724    0.00000      B  -0.026223   \n",
       "1     0.198272  242.00000  CHAS  -0.002278    0.00000     ZN  -0.003397   \n",
       "2     0.490302    0.46900   TAX   0.197083  242.00000      B   0.160604   \n",
       "3     0.956618  222.00000   NOX   0.442565    0.45800    AGE   0.204912   \n",
       "4     1.424987  222.00000  CRIM   0.528826    0.06905    NOX   0.463377   \n",
       "..         ...        ...   ...        ...        ...    ...        ...   \n",
       "501   0.130808    0.06263   TAX   0.071629  273.00000      B   0.062786   \n",
       "502   0.031415  273.00000    ZN   0.016322    0.00000      B   0.012697   \n",
       "503   0.266582    2.16750  CRIM   0.215512    0.06076    NOX   0.057181   \n",
       "504   0.289580    6.79400     B   0.058909  393.45000   CHAS  -0.002730   \n",
       "505  -0.003765    0.00000     B  -0.024175  396.90000  INDUS  -0.102163   \n",
       "\n",
       "     F5_value  \n",
       "0     396.900  \n",
       "1       0.000  \n",
       "2     392.830  \n",
       "3      45.800  \n",
       "4       0.458  \n",
       "..        ...  \n",
       "501   391.990  \n",
       "502   396.900  \n",
       "503     0.573  \n",
       "504     0.000  \n",
       "505    11.930  \n",
       "\n",
       "[506 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54fe3ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOX',\n",
       " 1.0789543390274048,\n",
       " 0.524,\n",
       " 'CRIM',\n",
       " 0.6521719098091125,\n",
       " 0.22489,\n",
       " 'PTRATIO',\n",
       " 0.6321080923080444,\n",
       " 15.2,\n",
       " 'B',\n",
       " 0.08092138171195984,\n",
       " 392.52,\n",
       " 'RAD',\n",
       " 0.053153250366449356,\n",
       " 5.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03ea7f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63232b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
